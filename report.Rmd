---
title: "Cross-selling in Banking"
author: Adrian Meier, Benjamin Wuermli
output:
  html_document:
    toc: yes
    toc_depth: '4'
    df_print: paged
    toc_float: true
  html_notebook:
    toc: yes
    toc_depth: 4
    df_print: paged
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    theme: united
    highlight: tango
    code_folding: show
---

# Einführung

## Aufgabenstellung

Eine tschechische Bank möchte ihre Dienstleistungen für Privatkunden verbessern und "interessante Kundengruppen" identifizieren. Die Geschäftsleitung hat keine präzise Vorstellung, möchte aber zusätzliches Business generieren ohne unnötige Risiken einzugehen und Verluste einzufahren.

Die Bank denkt, dass mit Hilfe von Data Science Informationen aus dem bestehenden Kundenstamm herausgeschält werden en können und liefert einen Datenextrakt aus der zentralen Datenbank. Dieser enthält Informationen zu Kunden, Produktbesitz und -nutzung (z.B. Kreditvolumen, Zahlungen, Daueraufträge und Kreditkarten), Filialnetz sowie soziodemographische Informationen.

Der analytische Auftrag besteht darin:

-   Qualität und Repräsentativität der Daten zu überprüfen

-   Die Verteilung der einzelnen Datenattribute zu erheben

-   Die Veränderung der Datenattribute über die Zeit zu analysieren

-   Korrelationen zwischen verschiedenen Datenattributen zu quantifizieren und zu visualisieren

-   Hypothesen hinsichtlich optimaler Produktverkauf / -nutzung zu erstellen

## Datengrundlage

Die Daten stammen laut der Aufgabenstellung von einer Tschechischen Bank und sind unter <https://sorry.vse.cz/~berka/challenge/PAST/index.html> downloadbar.

Die Daten enthalten 8 unterschiedliche csv Dateien, welche weiter unten im Bericht noch genauer erklärt werden.

# Imports

Um die Daten zu verarbeiten und zu visualisieren haben wir folgende Packages benötigt.

```{r message=FALSE}
required_packages <- c("tidyverse", "ggmosaic", "GGally", "randomForest", "caret", "ggridges", "cluster", "factoextra") # add more as needed

for (pkg in required_packages) {
    if (!require(pkg, character.only = TRUE)) {
        install.packages(pkg)
        library(pkg, character.only = TRUE)
    }
}
```

# Verfügbare Tabellen untersuchen

## account Datensatz

Der Account Datensatz besitz Informationen über die Account ID, aus welchem District der Account stammt, in welchem Intervall die Transaktionen ablaufen und wann der Account gegründet wurde.

```{r}
accounts <- read.csv("data/account.csv", sep=";")

#Ändern der tschechischen Namen in der Spalte frequency
accounts <- accounts %>%
  mutate(frequency = case_when(frequency == "POPLATEK MESICNE" ~ "Monatliche_Ausgabe",
                               frequency == "POPLATEK TYDNE" ~ "Wöchentliche_Ausgabe",
                               frequency == "POPLATEK PO OBRATU" ~ "Ausgabe_nach_Transaktion"))

#Frequency in Faktor umwandeln
accounts <- accounts %>% 
  mutate(frequency = as.factor(frequency))

# Datum umwandeln
accounts$date <- ymd(accounts$date)

# spalten umbenennen
accounts <- accounts %>%
  rename(opening_date = date,
         frequency_of_statements = frequency,
         district_id_account = district_id)
```

Die Daten wurden so angepasst, dass sie auf Deutsch sind und die Types entsprechend geändert werden.

Man sieht bei frequency die drei Ausgabedaten, zudem ist das Datum nun auch als Datum erfasst.

```{r message=FALSE}
glimpse(accounts)
summary(accounts)
sum(is.na(accounts))
length(unique(accounts$account_id)) == nrow(accounts)
```

Aus dem account Datensatz können wir nun sehen, woher unsere Accounts geographisch stammen dazu machen wir einen Bar Plot.

```{r}
barplot(table(accounts$district_id), main = "Distribution of Accounts by District", xlab = "District ID", ylab = "Number of Accounts")
```

Wir sehen das im deutlich mehr Accounts im Distrikt mit der ID 1 angesiedelt sind als ein allen anderen Distrikts. Dies ist auch nicht sonderlich überraschend, da es sich bei diesem Distrikt um Prag, der grössten Stadt im Land handelt.

Aus dem Datensatz kann man zudem einsehen, wann welche Accounts eröffnet wurden.

```{r}
ggplot(accounts, aes(x = opening_date, fill = as.factor(year(opening_date)))) +
  geom_histogram(binwidth = 7) +
  ggtitle("Accounteröffnungen pro Woche") +
  scale_fill_brewer(palette = "Set1") +
  labs(fill = "Jahr")

```

Es fällt auf, das gerade zu Beginn im ersten Jahr viele Accounts eröffnet wurden (rot eingefärbt), im Anschluss wurden zwei Jahre lang weniger Accounts eröffnet (blau und grün eingefärbt) und ab 1996 wurden es wieder mehr Eröffnungen (violett und orange eingefärbt).

## card Datensatz

Im card Datensatz befinden sich Informationen zu Kreditkarten. Wann diese ausgestellt wurden, welche Klasse sie haben und die ID vom Nutzer und der Karte.

```{r}
card <- read.csv("data/card.csv", sep=";")
```

Wir werden die Types angepasst und anschliessend wird die Spalte "issued" bearbeitet. Bei dieser sollen die ersten sechs Zeichen als Datum gewertet werden. Die 00:00:00 benötigen wir dabei nicht mehr, da diese bei allen Daten hintendran stehen.

```{r}
#Type in Faktor umwandeln
card <- card %>%
  rename(card_type = type)

card <- card %>% 
  mutate(card_type = as.factor(card_type))

# Datum umwandeln
card$issued <- ymd(substr(card$issued, 1, 6))

glimpse(card)
summary(card)
sum(is.na(card))
length(unique(card$card_id)) == nrow(card)
```

## client Datensatz

Der Datensatz client enthält Informationen über jeden Client, also eine ID, ein Geburtsdatum und den Standort. Wichtig ist auch zu wissen, dass der Client nicht gleich dem Account ist, es gibt Accounts, welche von mehreren Personen genutzt werden.

Bei diesem Datensatz ist zudem wichtig, dass in der birth_number zudem das Geschlecht gespeichert ist. Bei Frauen wurde die Angabe des Monats um 50 erhöht. D.h YYMMDD für Männer und YYMM+50DD für Frauen. Deshalb wollen wir eine zusätzliche Spalte für das Geschlecht erzeugen und die Geburtsdaten dann bereinigt in der birth number wiedergeben.

```{r}
client <- read.csv("data/client.csv", sep=";")

#Unterscheidung von Mann und Frau anhand vom Geburtsdatum
client <- client %>%
  mutate(
    sex = ifelse((birth_number %% 10000) > 2000, "female", "male")
  )

#Ändern des Datentyps der Reihe
client <- client %>% 
  mutate(sex = as.factor(sex))

#Geburtsdatum bei den Frauen um 5000 subtrahieren. Damit wieder der normale Monat angezeigt wird.
client$birth_number[client$sex == "female"] <- client$birth_number[client$sex == "female"]-5000


#Der <int> wird in ein Datum umgewandelt.
client <- client %>%
  mutate(birth_number = birth_number + 19000000)
client$birth_number <- ymd(client$birth_number)

client <- client %>%
  rename(birthday = birth_number,
         district_id_client = district_id)

client$year <- year(client$birthday)
```

Der Client Datensatz sollte nun korrekt sein und die Spalte "sex" enthalten.

```{r}
glimpse(client)
summary(client)
sum(is.na(client))
length(unique(client$client_id)) == nrow(client)
```

Nun wissen wir auch welches Alter und Geschlecht unsere Kunden haben. 
Dies können wir in einem Density Plot darstellen.

```{r}
ggplot(client, aes(x = year, fill = sex)) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Verteilung der Kunden nach Jahr und Geschlecht",
       x = "Jahr",
       y = "Dichte",
       fill = "Geschlecht")

```

Wir sehen, dass die Verteilung der Männer und Frauen in allen Altersklassen sehr ähnlich ist. Und das die meisten unserer Kunden im Alter zwischen 20 und 60 sind.

## disp Datensatz

Im disp Datensatz ist die Verknüpfung der Kunden mit den Accounts und ihre jeweilige Funktion dargestellt.
Hier müssen wir nur den type von character in factor ändern und anschliessend kontrollieren.

```{r}
disp <- read.csv("data/disp.csv", sep=";")

#Type in Faktor umwandeln
disp <- disp %>% 
  mutate(type = as.factor(type))

#Ausgabe von disp zur Kontrolle
glimpse(disp)
summary(disp)
sum(is.na(disp))
length(unique(disp$disp_id)) == nrow(disp)
```

## district Datensatz

Der district Datensatz enthält viele Informationen über jeden Distrikt.

Hier werden alle Spalten mit A angegeben, dies sollen aussagekräftigere Namen ersetzt werden.

Danach sollen noch alle character in andere Formate geändert werden. Die Warnung nach Ausführung des Codes ist auf den Distrikt Jesenik bezogen. Dort ist in der Spalte unemploymant_rate_95 und commited_crimes_95 ein "?" eigetragen, dieser Wert wird mit NA ersetzt.

```{r warning=FALSE}
district <- read.csv("data/district.csv", sep=";")

#Spaltennamen ändern
colnames(district) <- c("district_id", "district_name", "region", "inhabitants", "municipalities_less_than_499", "municipalities_500_to_1999", "municipalities_2000_to_9999", "municipalities_10000_plus", "cities", "urban_inhabitants", "average_salary", "unemploymant_rate_95", "unemploymant_rate_96", "enterpreneurs_per_1000", "commited_crimes_95", "commited_crimes_96")

district <- district %>% 
  mutate(district_name = as.factor(district_name),
        region = as.factor(region),
        unemploymant_rate_95 = as.double(unemploymant_rate_95),
        commited_crimes_95 = as.integer(commited_crimes_95))

```

Kontrolle der geänderten Tabelle.

```{r}
glimpse(district)
summary(district)
sum(is.na(district))
length(unique(district$A1)) == nrow(district)
```

Wir haben uns bei der Analyse der Daten gefragt, ob es einen Zusammenhang zwischen der Arbeitslosenquote und der Anzahl der begangenen Verbrechen gibt.

```{r warning=FALSE}
district <- district %>%
  mutate(crimes_per_1000_1995 = commited_crimes_95/inhabitants*1000)

ggplot(district, aes(x = unemploymant_rate_96, y = crimes_per_1000_1995)) +
  geom_point(alpha = 0.5) +
  labs(title = "Scatter Plot of Unemployment Rate and Committed Crimes in 1995",
       x = "Unemployment Rate in 1995",
       y = "Committed Crimes per 1000 in 1995")
```

```{r}
district <- district %>%
  mutate(crimes_per_1000_1996 = (commited_crimes_96/inhabitants)*1000)

ggplot(district, aes(x = unemploymant_rate_96, y = crimes_per_1000_1996)) +
  geom_point(alpha = 0.5) +
  labs(title = "Scatter Plot of Unemployment Rate and Committed Crimes in 1996",
       x = "Unemployment Rate in 1996",
       y = "Committed Crimes per 1000 in 1996")
```

Bei der Betrachtung der beiden Plots fällt auf, dass es keinen merklichen Anstieg gibt, so wie es unsere Hypothese war. Was aber auffällt, ist das der vorderste Punkt, welcher fast keine Arbeitslosigkeit aufzeigt, enorm hoch ist. Bei diesem Punkt handelt es sich wieder um Prag.



## loan Datensatz

Der loan Datensatz ist für uns einer der Interessantesten Datensätze. In ihm sind sämtliche vergebenen Kredite abgelegt.
Hier muss nur dem Status einen besseren Namen gegeben werden und in einen Faktor umgewandelt werden.

```{r}
loan <- read.csv("data/loan.csv", sep=";")

#Ändern der Namen in Status
loan <- loan %>%
  mutate(status = case_when(status == "A" ~ "finished_ok",
                   status == "B" ~ "finished_not_payed",
                   status == "C" ~ "running_ok",
                   status == "D" ~ "running_client_in_dept"))

#Status in Faktor ändern
loan <- loan %>%
  mutate(status = as.factor(status))

loan <- loan %>%
  rename(loan_date = date)%>%
  mutate(loan_date = ymd(loan_date + 19000000))
```

Kontrolle der Änderungen.

```{r}
glimpse(loan)
summary(loan)
sum(is.na(loan))
length(unique(loan$loan_id)) == nrow(loan)
```

Wir wollen nun anschauen welche Höhe von Krediten von der Bank vergeben wurde.

```{r}
ggplot(loan, aes(x = amount)) +
  geom_histogram(binwidth = 10000, color = "blue") +
  scale_x_continuous(breaks = seq(0, max(loan$amount), by = 50000)) +
  ggtitle("Betrag der vergebenen Kredite")
```

Dabei fällt auf, dass es sich vor allem um kleinere Kredite handelt. Es gibt aber vereinzelt grössere Kredite.

Gibt es Accounts, welche zwei Mal einen Kredit bekommen haben?

```{r}
n = sum(duplicated(loan$account_id))
print(paste("Es gibt", n, "Accounts, welche zwei mal einen Kredit bezogen haben."))
```

```{r}
ggplot(loan, aes(x = duration, y = after_stat(count), fill = as.factor(duration))) +
  geom_bar() +
  labs(
    title = "Verteilung der Kreditlaufzeiten",
    subtitle = "nach Anzahl und Dauer der Kredite",
    x = "Laufzeit in Monaten",
    y = "Anzahl der Kredite",
    fill = "Dauer"
  )

```

## order Datensatz

Der Order Datensatz hat Informationen über monatlich fixe Transaktionen.

Hier sollen die beiden character in factor geändert werden. Auch sollen die Werte in k_symbol verständlich werden.

```{r}
order <- read.csv("data/order.csv", sep=";")

#K_symbol Werte verständlich machen
order <- order %>%
  mutate(k_symbol = case_when(k_symbol == "POJISTNE" ~ "insurrance payment",
                           k_symbol == "SIPO" ~ "household",
                           k_symbol == "LEASING" ~ "leasing",
                           k_symbol == "UVER" ~ "loan payment",
                           k_symbol == " " ~ NA,))

#Umwandlung in Faktor
order <- order %>%
  mutate(bank_to = as.factor(bank_to),
         k_symbol = as.factor(k_symbol))
```

Kontrolle der Daten.

```{r}
glimpse(order)
summary(order)
sum(is.na(order))
length(unique(order$order_id)) == nrow(order)
```

## trans Datensatz

Der trans Datensatz ist der Grösste Datensatz, in ihm sind sämtliche Transaktionen enthalten.

Hier ändern wir die Namen, formatieren date in ein Datum und machen Umwandlungen in Faktoren. Bei der spalte type werden in der Datenbeschreibung nur "PRIJEM" und "VYDAJ" beschrieben zudem kommt aber auch noch "VYBER" vor, dieser wird aber ansonsten als "withdrawal in cash" beschrieben, deshalb übernehmen wir dies auch hier.
```{r}
trans <- read.csv("data/trans.csv", sep=";")

# Type Werte verständlich machen
trans <- trans %>%
  mutate(type = case_when(type == "PRIJEM" ~ "credit",
                          type == "VYDAJ" ~ "withdrawal",
                          type == "VYBER" ~ "withdrawal in cash"))

# Operation Werte verständlich machen
trans <- trans %>%
  mutate(operation = case_when(operation == "VYBER KARTOU" ~ "creditcard withdrawal",
                               operation == "VKLAD" ~ "credit in cash",
                               operation == "PREVOD Z UCTU" ~ "collection from another bank",
                               operation == "VYBER" ~ "withdrawal in cash",
                               operation == "PREVOD NA UCET" ~ "remittance to another bank"))


# K_symbol Werte verständlich machen
trans <- trans %>%
  mutate(k_symbol = case_when(k_symbol == "POJISTNE" ~ "insurrance payment",
                              k_symbol == "SLUZBY" ~ "paymant for statement",
                              k_symbol == "UROK" ~ "interest credited",
                              k_symbol == "SANKC. UROK" ~ "sanction interest if negative balance",
                              k_symbol == "SIPO" ~ "household",
                              k_symbol == "DUCHOD" ~ "old age pension",
                              k_symbol == "UVER" ~ "loan payment"))

# Datum umwandeln
trans$date <- ymd(trans$date)

# Ändern in <fct>
trans <- trans %>%
  mutate(type = as.factor(type),
         operation = as.factor(operation),
         k_symbol = as.factor(k_symbol),
         bank = na_if(bank, ""),
         bank = as.factor(bank))

trans <- trans %>%
  rename(
    balance_after_transaction = balance,
    account_receiver = account,
    bank_receiver = bank,
  )
```

Kontrolle der Änderungen

```{r}
glimpse(trans)
summary(trans)
sum(is.na(trans))
sum(is.na(trans$trans_id))
length(unique(trans$trans_id)) == nrow(trans)
```

```{r}
ggplot(trans, aes(x = date, fill = as.factor(year(date)))) +
  geom_histogram(binwidth = 30) +
  ggtitle("Anzahl Transaktionen pro Monat") +
  scale_fill_brewer(palette = "Set1") +
  labs(fill = "Jahr",
       x = "Zeit",
       y = "Anzahl der Transaktionen")
```

In diesem Plot ist gut zu sehen, dass die Anzahl der Transaktionen pro Monat im Verlauf der Jahre deutlich zugenommen hat.

# Client Analytical Records

Um einheitlich mit den gleichen Daten zu arbeiten wollen wir ein konsolidiertes Dataframe erstellen. Dazu haben wir zuerst die Schnittstellen der einzelnen Datensätze visualisiert.

![](Key%20Value%20Datensätze.PNG)

Um das Konsolidierte Dataframe zu erhalten haben wir zuerst alle Datensätze, welche vorhanden sind und durch einfache joins verbindbar sind zusammengefügt.

```{r}
client_analytical_record <- accounts %>%
  left_join(disp %>% filter(type == "OWNER") %>%
              rename_with(~paste0("owner_", .), -account_id), by = "account_id") %>%
  left_join(disp %>% filter(type == "DISPONENT") %>%
              rename_with(~paste0("user_", .), -account_id), by = "account_id")


client_analytical_record <- client_analytical_record %>%
  select(-owner_type, -user_type)

client_analytical_record <- client_analytical_record %>%
  left_join(client, by = c("owner_client_id" = "client_id"))

client_analytical_record <- client_analytical_record %>%
  rename(
    owner_birthday = birthday,
    owner_district_id = district_id_client,
    owner_sex = sex
  )

client_analytical_record <- client_analytical_record %>%
  left_join(client, by = c("user_client_id" = "client_id"))

client_analytical_record <- client_analytical_record %>%
  rename(
    user_birthday = birthday,
    user_district_id = district_id_client,
    user_sex = sex
  )


client_analytical_record <- client_analytical_record %>%
  left_join(card, by = c("owner_disp_id" = "disp_id"))%>%
  rename(
    card_issued = issued,
  )

client_analytical_record_no_district <- client_analytical_record


client_analytical_record <- client_analytical_record %>%
  left_join(district, by = c("owner_district_id" = "district_id"))

client_analytical_record <- client_analytical_record %>%
  left_join(loan, by = "account_id") %>%
  rename(
    loan_amount = amount,
    loan_duration = duration,
    loan_payments = payments,
    loan_status = status
  )

client_analytical_record <- client_analytical_record %>%
  select(-year.x, -year.y)

# glimpse(client_analytical_record)
```

Bei den Transaktionen wollen wir nicht jede Transaktion einzeln an das konsolidierte Dataframe anhängen, sondern wollen nur die monatlichen Aktivitäten dokumentieren. Dazu erstellen wir ein Dataframe, dass die Einnahmen und Ausgaben pro Monat und Account zusammenfasst.

```{r}
trans_per_month <- trans %>%
  mutate(year_month = floor_date(date, unit = "month")) %>%
  group_by(account_id, year_month) %>%
  summarise(
    einnahmen = sum(amount[type == "credit"]),
    ausgaben = sum(amount[type == "withdrawal in cash" | type == "withdrawal"]), .groups = "drop"
    )
```

Es soll nun noch eine Spalte erstellt werden, um zu schauen, wieviel die verschiedenen Accounts jeweils am Ende des Monats haben. Da wir die Vermutung haben, dass alle zu Beginn mit 0 auf dem Konto gestartet haben überprüfen wir dies im ersten Schritt kurz.

```{r}
#Dataframe erstellen um zu überprüfen, bei welchen accounts der amount und die balance nach der Transaktion gleich sind beim erst möglichen Datum.
kontostand_erster_Zeitpunkt <- trans %>%
  group_by(account_id) %>%
  filter(balance_after_transaction == amount) %>%
  slice_min(date) %>%
  ungroup()

# Überprüfen, ob jede account_id im Datensatz enthalten ist
all(unique(trans$account_id) %in% unique(kontostand_erster_Zeitpunkt$account_id))
```

Da wir nun Wissen, dass alle Accounts mit 0 begonnen haben, können wir in der trans_per_month liste die Balances min den Werten der vorherigen Monaten berechnen.

```{r}
trans_per_month <- trans_per_month %>%
  group_by(account_id) %>%
  mutate(kontostand_ende_monat = cumsum(einnahmen - ausgaben)) %>%
  ungroup()
```

Es sollen nun alle Daten für jedes Konto erstellt werden, auch wenn zu diesem Zeitpunkt keine Transaktionen über dieses Konto gelaufen sind.

```{r}
#Alle Transaktionen für alle zeiträume erstellen.
trans_per_month <- trans_per_month %>%
  complete(year_month = seq.Date(min(year_month), max(year_month), by="month"), account_id) %>%
  mutate(einnahmen = ifelse(is.na(einnahmen), 0, einnahmen)) %>%
  mutate(ausgaben = ifelse(is.na(ausgaben), 0, ausgaben)) %>%
  group_by(account_id) %>%
  fill(kontostand_ende_monat) %>%
  ungroup() %>%
  mutate(kontostand_ende_monat = ifelse(is.na(kontostand_ende_monat), 0, kontostand_ende_monat),
         year_month = (format(year_month, "%Y-%m"))
         )
```

Trans_per_month ändern, so dass jeder Monat ein Attribut wird und der Account nur eine Zeile hat.

```{r}
trans_per_month_new <- trans_per_month %>%
  pivot_wider(
    id_cols = account_id,
    names_from = year_month,
    values_from = c(einnahmen, ausgaben, kontostand_ende_monat),
    names_sort = TRUE
  ) 
```

Die neue Trans_per_month_new Liste wird nun an das CAR angehängt.

```{r}
# client_analytical_record <- client_analytical_record %>%
#   left_join(trans_per_month_new, by = c("account_id" = "account_id"))
```

## Transaktionen für Accounts mit Kredit für 6 Monate vor Kreditaufname

Als nächstes erstellen wir ein Dataframe, welches die Transaktionen für alle Accounts mit Kredit für die 6 Monate vor Kreditaufnahme enthält.
Mit diesem Können wir dann das Verhalten der Kunden vor der Kreditaufnahme analysieren.

```{r}
accounts_with_loan <- loan$account_id
loan_dates <- loan$loan_date

transactions_accounts_with_loan <- trans %>%
  filter(account_id %in% accounts_with_loan) %>%
  group_by(account_id, date) %>%
  summarise(
    einnahmen = sum(amount[type == "credit"]),
    ausgaben = sum(amount[type == "withdrawal in cash" | type == "withdrawal"]), .groups = "drop"
    ) %>%
  complete(date = seq.Date(min(date), max(date), by = "day"), account_id, fill = list(einnahmen = 0, ausgaben = 0)) %>%
  group_by(account_id) %>%
  arrange(date) %>%
  mutate(saldo = cumsum(einnahmen - ausgaben)) %>%
  fill(saldo, .direction = "downup") %>%
  ungroup() %>%
  left_join(loan, by = "account_id") %>%
  mutate(days_before_loan = as.numeric(loan_date - date),
         weeks_before_loan = ceiling(days_before_loan / 7)
         ) %>%
  filter(days_before_loan >= 0 & days_before_loan <= 182)

# glimpse(transactions_accounts_with_loan)
# summary(transactions_accounts_with_loan)
```


```{r}
transactions_accounts_with_loan %>%
  group_by(days_before_loan, status) %>%
  summarize(median_saldo = median(saldo), .groups = "drop") %>%
  ggplot(aes(x = days_before_loan, y = median_saldo, group = status, color = status)) +
  geom_line() +
  geom_smooth(method = "loess", se = TRUE, aes(fill = status)) +
  scale_x_reverse() +
  scale_color_brewer(
    palette = "Pastel1",
    labels = c("Abgeschlossen mit Schulden", "Abbezahlt", "Laufend mit Schulden", "Laufend und OK"),
    name = "Status"
  ) +
  scale_fill_brewer(
    palette = "Pastel1",
    labels = c("Abgeschlossen mit Schulden", "Abbezahlt", "Laufend mit Schulden", "Laufend und OK"),
    name = "Status"
  ) +
  labs(
    title = "Verlauf des Kontostandes 6 Monate vor Kreditbeginn",
    subtitle = "Grupiert nach Kreditstatus",
    x = "Tage vor Kreditbeginn",
    y = "Median des Saldos",
    color = "Kreditstatus",
    fill = "Kreditstatus"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")  # Adjust legend position if needed


```
Wir sehen einen deutlichen Unterschied zwischen den Kunden, die den Kredit abbezahlt haben und denen, die den Kredit nicht abbezahlt haben. Die Kunden, die den Kredit abbezahlt haben oder einen laufenden Kredit ohne Schulden, haben einen deutlich höheren Saldo als die Kunden, die den Kredit nicht abbezahlt haben. Dies könnte darauf hindeuten, dass die Kunden, die den Kredit nicht abbezahlt haben, bereits vor der Kreditaufnahme finanzielle Probleme hatten.

```{r}
transactions_accounts_with_loan %>%
  distinct(loan_id, .keep_all = TRUE) %>%
  ggplot(aes(x = as.factor(duration), fill = factor(status, levels = c("running_client_in_dept", "finished_not_payed", "running_ok", "finished_ok")))) +
  geom_bar() +
  scale_fill_brewer(
    palette = "Pastel1",
    labels = c("Laufend mit Schulden", "Nicht bezahlt", "Laufend OK", "Abbezahlt"),
    name = "Kreditstatus"
  ) +
  labs(
    title = "Verteilung der Kreditlaufzeiten nach Status",
    subtitle = "Anzahl der Kredite gruppiert nach Laufzeit und aktuellem Status",
    x = "Laufzeit in Monaten",
    y = "Anzahl der Kredite",
    fill = "Kreditstatus"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1)) # X-Achsenbeschriftungen bei Bedarf drehen

```


# Random Forest

## Trainings Dataframe erstellen

Für das Training des Random Forests erstellen wir ein Dataframe, welches die Kennwerte wie Durchschnittlicher Kontostand, Einnahmen Ausgaben, Die Standartabweichungen der Einnahmen, Ausgaben und Kontostand, das Wachstum des Kontostandes der letzten 6 Monate vor Kreditbeginn für Kunden mir Kredit und für die ersten 6 Monate des letzten Jahres für Kunden ohne Kredit enthält.
Zusätzlich fügen wir noch die Daten des erstellten Client analytical Record an.

```{r}
# Removing columns that start with "loan_"
client_analytical_record_no_district <- client_analytical_record_no_district %>%
  select(-starts_with("loan_"))

# Ersrellen des df der counts ohne Kredit
transactions_accounts_no_loan_for_training <- trans %>%
  filter(!(account_id %in% loan$account_id)) %>%
  filter(date >= as.Date("1998-01-01") & date < as.Date("1998-07-01")) %>%
  group_by(account_id, date) %>%
  summarise(
    einnahmen = sum(amount[type == "credit"]),
    ausgaben = sum(amount[type == "withdrawal in cash" | type == "withdrawal"]), .groups = "drop"
    ) %>%
  complete(date = seq.Date(min(date), max(date), by = "day"), account_id, fill = list(einnahmen = 0, ausgaben = 0)) %>%
  group_by(account_id) %>%
  arrange(date) %>%
  mutate(saldo = cumsum(einnahmen - ausgaben)) %>%
  fill(saldo, .direction = "downup") %>%
  ungroup()

df_grouped_metrics_no_loan_for_training <- transactions_accounts_no_loan_for_training %>%
  group_by(account_id) %>%
  summarize(
    mean_einnahmen = mean(einnahmen, na.rm = TRUE),
    sd_einnahmen = sd(einnahmen, na.rm = TRUE),
    mean_ausgaben = mean(ausgaben, na.rm = TRUE),
    sd_ausgaben = sd(ausgaben, na.rm = TRUE),
    avg_change = mean(diff(saldo)),
    sd_change = sd(diff(saldo)),
    mean_saldo = mean(saldo, na.rm = TRUE),
    sd_saldo = sd(saldo, na.rm = TRUE),
    start_saldo = first(saldo),
    end_saldo = last(saldo),
    growth = end_saldo - start_saldo,
    max_drawdown = min(diff(saldo)),
    .groups = "drop"
  ) %>%
  select(-start_saldo, -end_saldo) %>%
  mutate(loan = 0)


# Ersrellen des df der counts mit Kredit
df_grouped_metrics_with_loan <- transactions_accounts_with_loan %>%
  group_by(account_id) %>%
  summarize(
    mean_einnahmen = mean(einnahmen, na.rm = TRUE),
    sd_einnahmen = sd(einnahmen, na.rm = TRUE),
    mean_ausgaben = mean(ausgaben, na.rm = TRUE),
    sd_ausgaben = sd(ausgaben, na.rm = TRUE),
    avg_change = mean(diff(saldo)),
    sd_change = sd(diff(saldo)),
    mean_saldo = mean(saldo, na.rm = TRUE),
    sd_saldo = sd(saldo, na.rm = TRUE),
    start_saldo = first(saldo),
    end_saldo = last(saldo),
    growth = end_saldo - start_saldo,
    max_drawdown = min(diff(saldo)),
    .groups = "drop"
  ) %>%
  select(-start_saldo, -end_saldo) %>%
  mutate(loan = 1)

# zusammenfügen der beiden df
df_grouped_metrics <- bind_rows(df_grouped_metrics_no_loan_for_training, df_grouped_metrics_with_loan)%>%
  mutate(loan = as.factor(loan)) %>%
  left_join(client_analytical_record, by = "account_id") %>%
  select(-contains("loan_"), -unemploymant_rate_95, -crimes_per_1000_1995, -commited_crimes_95, -district_name) %>%
  mutate(
    has_user = ifelse(is.na(user_birthday), 0, 1),
    owner_age = 1999 - year(owner_birthday),
    opening_year = year(opening_date),
    card_type = addNA(card_type),  
    card_type = fct_expand(card_type, "NoCard"),  # Add "NoCard" as a level
    card_type = fct_recode(card_type, "NoCard" = NA_character_)
    ) %>%
  pivot_wider(names_from = owner_sex, values_from = owner_sex,
              values_fill = list(owner_sex = 0),
              values_fn = list(owner_sex = length)) %>%
  pivot_wider(names_from = frequency_of_statements, values_from = frequency_of_statements,
              values_fill = list(frequency_of_statements = 0),
              values_fn = list(frequency_of_statements = length)) %>%
  
  pivot_wider(names_from = card_type, values_from = card_type,
              values_fill = list(card_type = 0),
              values_fn = list(card_type = length)) %>%
  select(-user_birthday, -card_id, -user_disp_id, -user_client_id, -owner_client_id, -owner_birthday, -user_district_id, -user_sex, -card_issued, -opening_date, -owner_disp_id)

glimpse(df_grouped_metrics)
```
## Training und Auswertung des Models

Mit dem erstellten Dataframe trainieren wir ein Random forest Model. Dafür splitten wir die daten und verwenden 80% für das Training und 20% für das Testen. Die Metriken Accuracy, Kappa und F1 werden ausgegeben.

```{r}
set.seed(123)
splitIndex_13 <- createDataPartition(df_grouped_metrics$loan, p = .8, list = FALSE)
train_set_13 <- df_grouped_metrics[splitIndex_13, ]
test_set_13 <- df_grouped_metrics[-splitIndex_13, ]

model_13 <- randomForest(loan ~ . - account_id, data = train_set_13, method = "rf")

predictions_13 <- predict(model_13, test_set_13)

conf_matrix <- confusionMatrix(predictions_13, test_set_13$loan, positive = "1")

printSelectedMetrics <- function(conf_matrix) {
  accuracy <- conf_matrix$overall["Accuracy"]
  kappa <- conf_matrix$overall["Kappa"]
  f1_score <- conf_matrix$byClass["F1"]
  cat("Accuracy:", accuracy, "\n")
  cat("Kappa:", kappa, "\n")
  cat("F1 Score:", f1_score, "\n")
}

```

Wir haben uns bei der Auswertung der Konfusionsmatrix auf folgende Kennzahlen beschränkt. Der Accuracy, welche die True Positive sowie negative zusammenzählt und dann durch die anzahl der Beobachtungen teil, Der F1-Score welcher besser geeignet, um auch bei unverteilten Daten eine präzise Angabe zu treffen, Und dem Kappa, dieser Wert gibt an, wie gross der unterschied vom Model im Vergleich zu einer zufälligen Auswertung aussieht.

```{r}
printSelectedMetrics(conf_matrix)
```
Anschliessend haben wir die wichtigsten Variablen des Models ausgegeben. Diese sind nach der MeanDecreaseGini sortiert. Dieser Wert gibt an, wie stark die Variable die Gini Impurity reduziert. Je höher der Wert desto wichtiger ist die Variable für das Model.
Wir sehen das die Wichtigsten Variablen mit den erstellten Kennwerten des Verhaltens zu tun haben, die Variablen der Kreditkarten Distrikte und der Geschlechter sind nicht so wichtig.
```{r}
getTopNVarImportance <- function(model, n) {
  # Extract variable importance
  var_importance <- importance(model)

  # Convert to data frame and sort by MeanDecreaseGini
  top_vars <- as.data.frame(var_importance) %>%
    rownames_to_column(var = "variable") %>%
    arrange(desc(MeanDecreaseGini)) %>%
    head(n)

  # Print the top n variables
  print(top_vars)
}

getTopNVarImportance(model_13, 11)
```
## Erstellen des Dataframs für die Predictions

Nach dem gleichen Schema wie bei dem Dataframe für das Training erstellen wir eines für die Predictions, mit dem Unterschied das wir für die daten nur Accounts ohne Kredit und das Verhalten der letzten 6 Monate verwenden. Somit können wir das aktuelle Verhalten der Kunden vergleichen.


```{r}
transactions_accounts_no_loan <- trans %>%
  filter(!(account_id %in% loan$account_id)) %>%
  filter(date >= as.Date("1998-07-01")) %>%
  group_by(account_id, date) %>%
  summarise(
    einnahmen = sum(amount[type == "credit"]),
    ausgaben = sum(amount[type == "withdrawal in cash" | type == "withdrawal"]), .groups = "drop"
    ) %>%
  complete(date = seq.Date(min(date), max(date), by = "day"), account_id, fill = list(einnahmen = 0, ausgaben = 0)) %>%
  group_by(account_id) %>%
  arrange(date) %>%
  mutate(saldo = cumsum(einnahmen - ausgaben)) %>%
  fill(saldo, .direction = "downup") %>%
  ungroup()


df_grouped_metrics_no_loan_today <- transactions_accounts_no_loan %>%
  group_by(account_id) %>%
  summarize(
    mean_einnahmen = mean(einnahmen, na.rm = TRUE),
    sd_einnahmen = sd(einnahmen, na.rm = TRUE),
    mean_ausgaben = mean(ausgaben, na.rm = TRUE),
    sd_ausgaben = sd(ausgaben, na.rm = TRUE),
    avg_change = mean(diff(saldo)),
    sd_change = sd(diff(saldo)),
    mean_saldo = mean(saldo, na.rm = TRUE),
    sd_saldo = sd(saldo, na.rm = TRUE),
    start_saldo = first(saldo),
    end_saldo = last(saldo),
    growth = end_saldo - start_saldo,
    max_drawdown = min(diff(saldo)),
    .groups = "drop"
  ) %>%
  select(-start_saldo, -end_saldo)  %>%
  left_join(client_analytical_record, by = "account_id") %>%
  select(-contains("loan_"), -unemploymant_rate_95, -crimes_per_1000_1995, -commited_crimes_95, -district_name) %>%
  mutate(
    has_user = ifelse(is.na(user_birthday), 0, 1),
    owner_age = 1999 - year(owner_birthday),
    opening_year = year(opening_date),
    card_type = addNA(card_type),  # Add NA as a level if it's not already
    card_type = fct_expand(card_type, "NoCard"),  # Add "NoCard" as a level
    card_type = fct_recode(card_type, "NoCard" = NA_character_)
    ) %>%
  pivot_wider(names_from = owner_sex, values_from = owner_sex,
              values_fill = list(owner_sex = 0),
              values_fn = list(owner_sex = length)) %>%
  pivot_wider(names_from = frequency_of_statements, values_from = frequency_of_statements,
              values_fill = list(frequency_of_statements = 0),
              values_fn = list(frequency_of_statements = length)) %>%
  
  pivot_wider(names_from = card_type, values_from = card_type,
              values_fill = list(card_type = 0),
              values_fn = list(card_type = length)) %>%
  select(-user_birthday, -card_id, -user_disp_id, -user_client_id, -owner_client_id, -owner_birthday, -user_district_id, -user_sex, -card_issued, -opening_date, -owner_disp_id)


```

## Rechnen der Predictions

Nun können wir die Predictions für die Kunden ohne Kredit erstellen. zusätzlich sortieren wir sie auch nach der Wahrscheinlichkeit das der Kunde einen Kredit aufnimmt. Somit können wir auch eine bestimmte Anzahl Kunden mit der höchsten Wahrscheinlichkeit für ein Angebot auswählen.

```{r}
# Predict using the Random Forest model on the new data
predicted_probabilities <- predict(model_13, df_grouped_metrics_no_loan_today, type = "prob")

# If you need to add these predictions as a new column to your df_grouped_metrics_no_loan_today dataframe:
df_grouped_metrics_no_loan_today$predictions <- ifelse(predicted_probabilities[, "1"] > 0.5, 1, 0)
# Add the predicted probabilities as new columns to your dataframe
df_grouped_metrics_no_loan_today$prob_0 <- predicted_probabilities[, "0"]
df_grouped_metrics_no_loan_today$prob_1 <- predicted_probabilities[, "1"]


# Sort the dataframe by the predicted probabilities for class 1 in descending order
df_sorted_by_prob <- df_grouped_metrics_no_loan_today %>%
  arrange(desc(prob_1)) %>%
  select(account_id, prob_1)

# Select the top n results
top_n_results <- head(df_sorted_by_prob, 10)

# View the top n results
print(top_n_results)
```
## Visuelle Darstellung der Predictions

Um das Visuell darzustellen haben wir uns entschieden das Verhalten Der Kunden über die letzten 6 Monate zu vergleichen.
Wir vergleichen dazu die Kunden, die bereits einen Kredit hatten mit denen die gute oder schlechte Kandidaten sind.
in diesen Plots ist zu sehen das die Kunden die gute Kandidaten sind sich gegen Ende sehr ähnlich verhalten wie die Kunden die bereits einen Kredit haben und auch ihre Raten zahlen. 

```{r}
ids_predicted_yes <- df_grouped_metrics_no_loan_today %>%
  filter(predictions == 1) %>%
  select(account_id)

ids_predicted_no <- df_grouped_metrics_no_loan_today %>%
  filter(predictions == 0) %>%
  select(account_id)


transactions_accounts_no_loan <- trans %>%
  filter(account_id %in% df_grouped_metrics_no_loan_today$account_id) %>%
  filter(date >= as.Date("1998-07-01")) %>%
  group_by(account_id, date) %>%
  summarise(
    einnahmen = sum(amount[type == "credit"]),
    ausgaben = sum(amount[type == "withdrawal in cash" | type == "withdrawal"]), .groups = "drop"
    ) %>%
  complete(date = seq.Date(min(date), max(date), by = "day"), account_id, fill = list(einnahmen = 0, ausgaben = 0)) %>%
  group_by(account_id) %>%
  arrange(date) %>%
  mutate(saldo = cumsum(einnahmen - ausgaben)) %>%
  fill(saldo, .direction = "downup") %>%
  ungroup() %>%
  mutate(predictions = ifelse(account_id %in% ids_predicted_yes$account_id, 1, 0),
         predictions = as.factor(predictions))


test1 <- transactions_accounts_with_loan %>%
  mutate(predictions = as.factor(-1)) %>%
  select(account_id, einnahmen, ausgaben, saldo, days_before_loan, predictions)
 
test2 <- transactions_accounts_no_loan %>%
  mutate(days_before_loan = as.numeric(as.Date("1999-01-01") - date)) %>%
  select(!date)
 
plot_df <- bind_rows(test1, test2)
 
plot_df %>%
  group_by(days_before_loan, predictions) %>%
  summarize(gemitteltes_saldo = mean(saldo), .groups = "drop") %>%
  ggplot(aes(x = days_before_loan, y = gemitteltes_saldo, group = predictions, color = as.factor(predictions))) +
  geom_line() +
  geom_smooth(method = "loess", se = TRUE, aes(fill = as.factor(predictions))) +
  scale_color_manual(values = c("green","orangered","deepskyblue"), 
                     labels = c("Bereits", "Nein", "Ja"),
                     name = "Kreditkandidaten") +
  scale_fill_manual(values = c("green","orangered","deepskyblue"), 
                    labels = c("Bereits", "Nein", "Ja"),
                    name = "Kreditkandidaten") +
  labs(title = "Durchschnittlicher Kontostand im letzten Jahr",
       x = "Tage vor dem Kredit",
       y = "Kontostand") +
  scale_x_reverse() +
  theme_minimal()
 
plot_df %>%
  group_by(days_before_loan, predictions) %>%
  summarize(median_saldo = median(saldo), .groups = "drop") %>%
  ggplot(aes(x = days_before_loan, y = median_saldo, group = predictions, color = as.factor(predictions))) +
  geom_line() +
  geom_smooth(method = "loess", se = TRUE, aes(fill = as.factor(predictions))) +
  scale_color_manual(values = c("green","orangered","deepskyblue"), 
                     labels = c("Bereits", "Nein", "Ja"),
                     name = "Kreditkandidaten") +
  scale_fill_manual(values = c("green","orangered","deepskyblue"), 
                    labels = c("Bereits", "Nein", "Ja"),
                    name = "Kreditkandidaten") +
  labs(title = "Median des Kontostandes im letzten Jahr",
       x = "Tage vor dem Kredit",
       y = "Kontostand") +
  scale_x_reverse() +
  theme_minimal()
 
plot_df %>%
  group_by(days_before_loan, predictions) %>%
  summarize(gemittelte_einnahmen = mean(einnahmen), .groups = "drop") %>%
  ggplot(aes(x = days_before_loan, y = gemittelte_einnahmen, group = predictions, color = as.factor(predictions))) +
  geom_line() +
  geom_smooth(method = "loess", se = TRUE, aes(fill = as.factor(predictions))) +
  scale_color_manual(values = c("green","orangered","deepskyblue"), 
                     labels = c("Bereits", "Nein", "Ja"),
                     name = "Kreditkandidaten") +
  scale_fill_manual(values = c("green","orangered","deepskyblue"), 
                    labels = c("Bereits", "Nein", "Ja"),
                    name = "Kreditkandidaten") +
  labs(title = "Durchschnitliche Einnahmen im letzten Jahr",
       x = "Tage vor dem Kredit",
       y = "Einnahmen") +
  scale_x_reverse() +
  theme_minimal()
 
plot_df %>%
  group_by(days_before_loan, predictions) %>%
  summarize(gemittelte_ausgaben = mean(ausgaben), .groups = "drop") %>%
  ggplot(aes(x = days_before_loan, y = gemittelte_ausgaben, group = predictions, color = as.factor(predictions))) +
  geom_line() +
  geom_smooth(method = "loess", se = TRUE, aes(fill = as.factor(predictions))) +
  scale_color_manual(values = c("green","orangered","deepskyblue"), 
                     labels = c("Bereits", "Nein", "Ja"),
                     name = "Kreditkandidaten") +
  scale_fill_manual(values = c("green","orangered","deepskyblue"), 
                    labels = c("Bereits", "Nein", "Ja"),
                    name = "Kreditkandidaten") +
  labs(title = "Durchschnitliche Ausgaben im letzten Jahr",
       x = "Tage vor dem Kredit",
       y = "Ausgaben") +
  scale_x_reverse() +
  theme_minimal()
```


# Fazid

## Ergebnis 
Wir haben gesehen, dass unser Model sehr zuverlässig Kandidaten für einen Kredit auswählen kann, dabei ist vor allem der Saldo für das Model äusserst wichtig. Was auch auffallend ist, ist dass die Einnahmen, Ausgaben und der Saldo deutlich höher sind für die Kunden welche einen Kredit bekommen, im Vergleich zu denen welche keinen bekommen. Die Anzahl der Ausgabe, wer für einen Kredit interessant wäre ist nicht sonderlich hoch, dafür sollten durch die hohe Genauigkeit des Models auch nur ein Kunde, welcher an einem Kredit interessiert ist. Wir haben uns beim Model auf eine Zeitdauer von sechs Monaten beschränkt. Wir haben das Model zuerst mit 13 Monaten laufen lassen, das Problem dabei war, dass die Kunden, welche bereits einen Kredit genommen haben zum Teil erst seit kurzem überhaupt ein Konto besitzen und Geld auf dieses einzahlen, so war der Median 13 Monate im Voraus zum Teil kurz vor Null. Nach der Anpassung auf sechs Monate hat sich auch die Genauigkeit unseres Models noch einmal gesteigert.

## Reflexion 
Wir haben viel gelernt während dieser Challenge, angefangen bei vielen kleinen Aufgaben eine richtige Syntax in R zu erstellen, dabei haben wir auch die Hilfe von ChatGPT benötigt, dabei war es gerade bei kleinen Problemen, wie beim Optimieren von Plots oft hilfreich. Grössere Probleme wie das Generieren von ganzen Codeblocks war wiederum oft mühsamer, unpräzise und es brauchte viel Zeit zum Überarbeiten im Nachhinein. Zudem haben wir gelernt, dass es für eine zukünftige Aufgabe auch sinnvoll ist, auch während dem Projekt das Notebook etwas aufzuräumen denn gerade beim Abschluss unserer Arbeit haben wir noch einmal viel Zeit für das Aufräumen und Korrigieren des Notebooks aufgewendet. Abschliessend können wir sagen, dass wir in diesem Projekt trotzdem wir manchmal sehr genervt waren, wenn etwas nicht funktioniert hat, wofür man einige Zeit aufgewendet hat, viel Neues, Nützliches und Interessantes gelernt haben.
